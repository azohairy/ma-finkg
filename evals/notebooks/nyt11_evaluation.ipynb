{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "jfu12ups4df",
   "metadata": {},
   "source": [
    "## NYT11-HRL Relation Extraction Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a32a3e63",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-08T15:16:33.241751Z",
     "iopub.status.busy": "2024-08-08T15:16:33.241338Z",
     "iopub.status.idle": "2024-08-08T15:16:34.199920Z",
     "shell.execute_reply": "2024-08-08T15:16:34.198687Z"
    },
    "papermill": {
     "duration": 0.971425,
     "end_time": "2024-08-08T15:16:34.202851",
     "exception": false,
     "start_time": "2024-08-08T15:16:33.231426",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import hashlib\n",
    "import json\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e8cfafc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zohairy/projects/multi-agent/kg_env/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /Users/zohairy/.cache/kagglehub/datasets/dykphd/nyt11-hrl-re/versions/1\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"dykphd/nyt11-hrl-re\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "abcb80ec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-08T15:16:34.221345Z",
     "iopub.status.busy": "2024-08-08T15:16:34.220823Z",
     "iopub.status.idle": "2024-08-08T15:16:34.226485Z",
     "shell.execute_reply": "2024-08-08T15:16:34.225320Z"
    },
    "papermill": {
     "duration": 0.0175,
     "end_time": "2024-08-08T15:16:34.228937",
     "exception": false,
     "start_time": "2024-08-08T15:16:34.211437",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "file_path = {\n",
    "    \"train\": f\"{path}/nyt11/train.json\",\n",
    "    \"test\": f\"{path}/nyt11/test.json\",\n",
    "    \"test-plus\": f\"{path}/nyt11/test-plus.json\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02679072",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-08T15:16:34.263925Z",
     "iopub.status.busy": "2024-08-08T15:16:34.263538Z",
     "iopub.status.idle": "2024-08-08T15:16:34.281142Z",
     "shell.execute_reply": "2024-08-08T15:16:34.279706Z"
    },
    "papermill": {
     "duration": 0.030073,
     "end_time": "2024-08-08T15:16:34.284307",
     "exception": false,
     "start_time": "2024-08-08T15:16:34.254234",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"sentext\": \" But that spasm of irritation by a master intimidator was minor compared with what Bobby Fischer , the erratic former world chess champion , dished out in March at a news conference in Reykjavik , Iceland . \", \"entities\": [\"Bobby Fischer\", \"Reykjavik\", \"Iceland\"], \"ID\": 1, \"relations\": [{\"rtext\": \"/people/person/nationality\", \"em2\": \"Iceland\", \"em1\": \"Bobby Fischer\", \"tags\": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 6, 0, 5, 0]}, {\"rtext\": \"/location/country/capital\", \"em2\": \"Reykjavik\", \"em1\": \"Iceland\", \"tags\": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 6, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 4, 0]}, {\"rtext\": \"/people/deceased_person/place_of_death\", \"em2\": \"Reykjavik\", \"em1\": \"Bobby Fischer\", \"tags\": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 6, 0]}]}\n",
      "\n",
      "{\"sentext\": \" But Schaap seems as comfortable in that role as Joe Buck , the Fox baseball and football sportscaster who so clearly benefited from learning beside his father , Jack Buck , the late voice of the St. Louis Cardinals . '' \", \"entities\": [\"St. Louis Cardinals\", \"Jack Buck\", \"Joe Buck\", \"Fox\"], \"ID\": 2, \"relations\": [{\"rtext\": \"/people/person/children\", \"em2\": \"Joe Buck\", \"em1\": \"Jack Buck\", \"tags\": [0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 2, 0, 0, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 1, 0, 0, 0, 0, 0, 0, 6, 3, 3, 0, 0]}]}\n",
      "\n",
      "{\"sentext\": \" www.bonhams.com July 22 Mecum Hawkeye Classic Auction , Iowa Sate Fairgrounds , Des Moines . \", \"entities\": [\"Des Moines\", \"Iowa\"], \"ID\": 3, \"relations\": [{\"rtext\": \"/location/location/contains\", \"em2\": \"Des Moines\", \"em1\": \"Iowa\", \"tags\": [0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 5, 2, 0]}]}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(file_path[\"train\"]) as f:\n",
    "    for i in range(3):\n",
    "        print(f.readline())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be6b4300",
   "metadata": {
    "papermill": {
     "duration": 0.007899,
     "end_time": "2024-08-08T15:16:34.300721",
     "exception": false,
     "start_time": "2024-08-08T15:16:34.292822",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b2f5343",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-08T15:16:34.319351Z",
     "iopub.status.busy": "2024-08-08T15:16:34.318757Z",
     "iopub.status.idle": "2024-08-08T15:16:34.329090Z",
     "shell.execute_reply": "2024-08-08T15:16:34.327942Z"
    },
    "papermill": {
     "duration": 0.022998,
     "end_time": "2024-08-08T15:16:34.331842",
     "exception": false,
     "start_time": "2024-08-08T15:16:34.308844",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fix_json_format(file_path, save_fixed=False) -> str:\n",
    "    with open(file_path, \"r\") as f:\n",
    "        mal_formatted_json = f.read()\n",
    "    \n",
    "    # Add comma before newline\n",
    "    comma_fixed = re.sub(r\"\\n\", \",\\n\", mal_formatted_json)\n",
    "    \n",
    "    # Remove comma after last elements because JSON standard does not allow \"trailing comma\" (https://www.json.org/json-en.html)\n",
    "    print(f\"{file_path}: checking trailing comma - {repr(comma_fixed[-10:])}\")\n",
    "    comma_fixed = comma_fixed[:-2]\n",
    "    \n",
    "    # Make it a list\n",
    "    list_fixed = \"[\" + comma_fixed + \"]\"\n",
    "\n",
    "    # Save the fixed JSON data\n",
    "    if save_fixed:\n",
    "        file_path = pathlib.Path(file_path)\n",
    "        parent = file_path.parent\n",
    "        name = file_path.stem\n",
    "        save_path = parent / f\"{name}_fixed.json\"\n",
    "        with open(save_path, \"w\") as f:\n",
    "            f.write(list_fixed)\n",
    "        print(f\"{file_path}: fixed json saved to file - {save_path}\")\n",
    "\n",
    "    return list_fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44d0c5ce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-08T15:16:34.350451Z",
     "iopub.status.busy": "2024-08-08T15:16:34.349859Z",
     "iopub.status.idle": "2024-08-08T15:16:34.871288Z",
     "shell.execute_reply": "2024-08-08T15:16:34.869953Z"
    },
    "papermill": {
     "duration": 0.533709,
     "end_time": "2024-08-08T15:16:34.873986",
     "exception": false,
     "start_time": "2024-08-08T15:16:34.340277",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/zohairy/.cache/kagglehub/datasets/dykphd/nyt11-hrl-re/versions/1/nyt11/train.json: checking trailing comma - '5, 0]}]},\\n'\n",
      "/Users/zohairy/.cache/kagglehub/datasets/dykphd/nyt11-hrl-re/versions/1/nyt11/test.json: checking trailing comma - '0, 0]}]},\\n'\n",
      "/Users/zohairy/.cache/kagglehub/datasets/dykphd/nyt11-hrl-re/versions/1/nyt11/test-plus.json: checking trailing comma - 'her . \"},\\n'\n"
     ]
    }
   ],
   "source": [
    "train_fixed_str = fix_json_format(file_path[\"train\"], save_fixed=False)\n",
    "test_fixed_str = fix_json_format(file_path[\"test\"], save_fixed=False)\n",
    "test_plus_fixed_str = fix_json_format(file_path[\"test-plus\"], save_fixed=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d91ea2",
   "metadata": {
    "papermill": {
     "duration": 0.008445,
     "end_time": "2024-08-08T15:16:34.891504",
     "exception": false,
     "start_time": "2024-08-08T15:16:34.883059",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Data Conversion to Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a574aae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-08T15:16:34.910663Z",
     "iopub.status.busy": "2024-08-08T15:16:34.909725Z",
     "iopub.status.idle": "2024-08-08T15:16:36.079585Z",
     "shell.execute_reply": "2024-08-08T15:16:36.078255Z"
    },
    "papermill": {
     "duration": 1.182625,
     "end_time": "2024-08-08T15:16:36.082569",
     "exception": false,
     "start_time": "2024-08-08T15:16:34.899944",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_fixed_json = json.loads(train_fixed_str)\n",
    "test_fixed_json = json.loads(test_fixed_str)\n",
    "test_plus_fixed_json = json.loads(test_plus_fixed_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0fc2e30d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-08T15:16:36.102283Z",
     "iopub.status.busy": "2024-08-08T15:16:36.101844Z",
     "iopub.status.idle": "2024-08-08T15:16:36.111485Z",
     "shell.execute_reply": "2024-08-08T15:16:36.110284Z"
    },
    "papermill": {
     "duration": 0.02255,
     "end_time": "2024-08-08T15:16:36.114355",
     "exception": false,
     "start_time": "2024-08-08T15:16:36.091805",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def json_to_pandas(json_data) -> pd.DataFrame:\n",
    "    triples = []\n",
    "    for e in json_data:\n",
    "        \"\"\"\n",
    "        - Definition of Triples: (subject, predicate, object) pairs\n",
    "        - Column Description:\n",
    "            - sentext: input sentence.\n",
    "            - em1: subject\n",
    "            - rtext: predicate\n",
    "            - em2: object\n",
    "        - Note\n",
    "            - There are cases that one sentence has more than one triples.\n",
    "            - Therefore, hashed `sentext` is used for unique `id`.\n",
    "            - The `tags` data is omitted because I am only intereseted in entities and relationship between them.\n",
    "        \"\"\"\n",
    "        id = hashlib.md5()\n",
    "        id.update(e[\"sentext\"].encode(\"utf-8\"))\n",
    "        for r in e[\"relations\"]:\n",
    "            t = {\n",
    "                \"id\": id.hexdigest(),\n",
    "                \"sentext\": e[\"sentext\"],\n",
    "                \"entities\": e[\"entities\"],\n",
    "                \"em1\": r[\"em1\"],\n",
    "                \"rtext\": r[\"rtext\"],\n",
    "                \"em2\": r[\"em2\"],\n",
    "                # \"tags\": r[\"tags\"]\n",
    "            }\n",
    "            triples.append(t)\n",
    "    return pd.DataFrame.from_dict(triples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "97cf08b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-08T15:16:36.132870Z",
     "iopub.status.busy": "2024-08-08T15:16:36.132519Z",
     "iopub.status.idle": "2024-08-08T15:16:36.697308Z",
     "shell.execute_reply": "2024-08-08T15:16:36.696133Z"
    },
    "papermill": {
     "duration": 0.577473,
     "end_time": "2024-08-08T15:16:36.700175",
     "exception": false,
     "start_time": "2024-08-08T15:16:36.122702",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df = json_to_pandas(train_fixed_json)\n",
    "test_df = json_to_pandas(test_fixed_json)\n",
    "test_plus_df = json_to_pandas(test_plus_fixed_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f1c22d",
   "metadata": {
    "papermill": {
     "duration": 0.007915,
     "end_time": "2024-08-08T15:16:36.742819",
     "exception": false,
     "start_time": "2024-08-08T15:16:36.734904",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### NYT11 Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c316200",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-08T15:20:58.531949Z",
     "iopub.status.busy": "2024-08-08T15:20:58.530712Z",
     "iopub.status.idle": "2024-08-08T15:20:58.562552Z",
     "shell.execute_reply": "2024-08-08T15:20:58.561349Z"
    },
    "papermill": {
     "duration": 0.044865,
     "end_time": "2024-08-08T15:20:58.565084",
     "exception": false,
     "start_time": "2024-08-08T15:20:58.520219",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369b9dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740963ee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-08T15:20:58.586938Z",
     "iopub.status.busy": "2024-08-08T15:20:58.586516Z",
     "iopub.status.idle": "2024-08-08T15:20:58.613948Z",
     "shell.execute_reply": "2024-08-08T15:20:58.612931Z"
    },
    "papermill": {
     "duration": 0.042014,
     "end_time": "2024-08-08T15:20:58.616448",
     "exception": false,
     "start_time": "2024-08-08T15:20:58.574434",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_plus_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1863ddd",
   "metadata": {
    "papermill": {
     "duration": 0.009125,
     "end_time": "2024-08-08T15:20:58.635173",
     "exception": false,
     "start_time": "2024-08-08T15:20:58.626048",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Getting Unique Predicates (Relationships)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c91b8935",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-08T15:20:58.655690Z",
     "iopub.status.busy": "2024-08-08T15:20:58.655322Z",
     "iopub.status.idle": "2024-08-08T15:20:58.672334Z",
     "shell.execute_reply": "2024-08-08T15:20:58.671201Z"
    },
    "papermill": {
     "duration": 0.030479,
     "end_time": "2024-08-08T15:20:58.675064",
     "exception": false,
     "start_time": "2024-08-08T15:20:58.644585",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_rtext = list(train_df[\"rtext\"].unique())\n",
    "test_rtext = list(test_df[\"rtext\"].unique())\n",
    "test_plus_rtext = list(test_plus_df[\"rtext\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883bc796",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-08T15:20:58.695961Z",
     "iopub.status.busy": "2024-08-08T15:20:58.695542Z",
     "iopub.status.idle": "2024-08-08T15:20:58.701006Z",
     "shell.execute_reply": "2024-08-08T15:20:58.699806Z"
    },
    "papermill": {
     "duration": 0.018597,
     "end_time": "2024-08-08T15:20:58.703369",
     "exception": false,
     "start_time": "2024-08-08T15:20:58.684772",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_rtext.sort()\n",
    "test_rtext.sort()\n",
    "test_plus_rtext.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad5bc1f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-08T15:20:58.724331Z",
     "iopub.status.busy": "2024-08-08T15:20:58.723837Z",
     "iopub.status.idle": "2024-08-08T15:20:58.730579Z",
     "shell.execute_reply": "2024-08-08T15:20:58.729333Z"
    },
    "papermill": {
     "duration": 0.02001,
     "end_time": "2024-08-08T15:20:58.733093",
     "exception": false,
     "start_time": "2024-08-08T15:20:58.713083",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"Predicates in train set:\\n{train_rtext}\\n\")\n",
    "print(f\"Predicates in test set:\\n{test_rtext}\\n\")\n",
    "print(f\"Predicates in test-plus set:\\n{test_plus_rtext}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4ab209",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-08T15:20:58.782862Z",
     "iopub.status.busy": "2024-08-08T15:20:58.781997Z",
     "iopub.status.idle": "2024-08-08T15:20:58.789677Z",
     "shell.execute_reply": "2024-08-08T15:20:58.788361Z"
    },
    "papermill": {
     "duration": 0.02112,
     "end_time": "2024-08-08T15:20:58.792280",
     "exception": false,
     "start_time": "2024-08-08T15:20:58.771160",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "unique_rtext = list(set(train_rtext + test_rtext + test_plus_rtext))\n",
    "unique_rtext"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c831d07",
   "metadata": {},
   "source": [
    "### NYT11-HRL Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5osuoqhdut6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize KG System for evaluation\n",
    "import sys\n",
    "import os\n",
    "sys.path.append('../../src/ma_finkg')\n",
    "\n",
    "from kg_construction_graph import FinancialKGConstructionGraph\n",
    "from utils import set_global_timer\n",
    "\n",
    "# Set OpenRouter API key and model\n",
    "openrouter_key = \"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\"\n",
    "model = \"openai/gpt-3.5-turbo\"\n",
    "\n",
    "# Set API key and initialize\n",
    "os.environ[\"OPENROUTER_API_KEY\"] = openrouter_key\n",
    "test=\"nyt11\"\n",
    "kg_system = FinancialKGConstructionGraph(model_name=model, ontology=test, prompts=test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4db1ca9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 10/10 remaining sentences...\n",
      "Processing sentence 1/10...\n",
      "[0.0s] Starting knowledge graph construction...\n",
      "[0.9s] Creating ontology...\n",
      "\n",
      "[ONTOLOGY] Using predefined nyt11 ontology (no LLM call needed)\n",
      "[1.5s] Extracting entities and relations...\n",
      "[3.4s] NER completed: 3 entities                                                                    \n",
      "[18.1s] RE completed: 8 filtered triples                                                            \n",
      "\n",
      "[REVISION] Validated: 3/3 entities, 8/8 triples\n",
      "[18.7s] Finalizing results...\n",
      "[18.7s] Construction completed!\n",
      "Processing sentence 2/10...\n",
      "[0.0s] Starting knowledge graph construction...\n",
      "[0.5s] Creating ontology...\n",
      "\n",
      "[ONTOLOGY] Using predefined nyt11 ontology (no LLM call needed)\n",
      "[1.1s] Extracting entities and relations...\n",
      "[2.8s] NER completed: 3 entities                                                                    \n",
      "[18.3s] RE completed: 9 filtered triples                                                            \n",
      "\n",
      "[REVISION] Validated: 3/3 entities, 9/9 triples\n",
      "[18.8s] Finalizing results...\n",
      "[18.8s] Construction completed!\n",
      "Processing sentence 3/10...\n",
      "[0.0s] Starting knowledge graph construction...\n",
      "[0.5s] Creating ontology...\n",
      "\n",
      "[ONTOLOGY] Using predefined nyt11 ontology (no LLM call needed)\n",
      "[1.1s] Extracting entities and relations...\n",
      "[2.7s] NER completed: 2 entities                                                                    \n",
      "[14.9s] RE completed: 0 filtered triples                                                            \n",
      "\n",
      "[REVISION] Validated: 2/2 entities, 0/0 triples\n",
      "[15.5s] Finalizing results...\n",
      "[15.5s] Construction completed!\n",
      "Processing sentence 4/10...\n",
      "[0.0s] Starting knowledge graph construction...\n",
      "[0.8s] Creating ontology...\n",
      "\n",
      "[ONTOLOGY] Using predefined nyt11 ontology (no LLM call needed)\n",
      "[1.6s] Extracting entities and relations...\n",
      "[4.0s] NER completed: 5 entities                                                                    \n",
      "[36.8s] RE completed: 53 filtered triples                                                           \n",
      "\n",
      "[REVISION] Validated: 5/5 entities, 53/53 triples\n",
      "[37.6s] Finalizing results...\n",
      "[37.6s] Construction completed!\n",
      "Processing sentence 5/10...\n",
      "[0.0s] Starting knowledge graph construction...\n",
      "[0.8s] Creating ontology...\n",
      "\n",
      "[ONTOLOGY] Using predefined nyt11 ontology (no LLM call needed)\n",
      "[1.7s] Extracting entities and relations...\n",
      "[3.8s] NER completed: 6 entities                                                                    \n",
      "[3.8s] Processing relation 1/12: /location/administrative_division/country                          "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 52\u001b[39m\n\u001b[32m     50\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m text \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m sentence_cache:\n\u001b[32m     51\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mProcessing sentence \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(processed_sentences)\u001b[38;5;250m \u001b[39m+\u001b[38;5;250m \u001b[39msentence_idx\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(sentence_relations)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m     result = \u001b[43mkg_system\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconstruct_kg\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     53\u001b[39m     sys_triples = result[\u001b[33m'\u001b[39m\u001b[33mfinalize\u001b[39m\u001b[33m'\u001b[39m].get(\u001b[33m\"\u001b[39m\u001b[33mrevised_triples\u001b[39m\u001b[33m\"\u001b[39m, []) \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33mfinalize\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m result \u001b[38;5;28;01melse\u001b[39;00m []\n\u001b[32m     55\u001b[39m     sys_relations = []\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/multi-agent/financial_kg_system/evals/notebooks/../../src/ma_finkg/kg_construction_graph.py:184\u001b[39m, in \u001b[36mFinancialKGConstructionGraph.construct_kg\u001b[39m\u001b[34m(self, financial_text, config)\u001b[39m\n\u001b[32m    181\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._process_chunks(chunks, financial_text, config)\n\u001b[32m    183\u001b[39m \u001b[38;5;66;03m# Original processing for normal-sized texts\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m184\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_process_single_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfinancial_text\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/multi-agent/financial_kg_system/evals/notebooks/../../src/ma_finkg/kg_construction_graph.py:198\u001b[39m, in \u001b[36mFinancialKGConstructionGraph._process_single_text\u001b[39m\u001b[34m(self, financial_text, config)\u001b[39m\n\u001b[32m    196\u001b[39m \u001b[38;5;66;03m# Execute the graph\u001b[39;00m\n\u001b[32m    197\u001b[39m final_state = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m198\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\u001b[43minitial_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    199\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfinal_state\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\n\u001b[32m    201\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Print progress with timing\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/multi-agent/kg_env/lib/python3.13/site-packages/langgraph/pregel/main.py:2647\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, subgraphs, debug, **kwargs)\u001b[39m\n\u001b[32m   2645\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m loop.match_cached_writes():\n\u001b[32m   2646\u001b[39m     loop.output_writes(task.id, task.writes, cached=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m2647\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2648\u001b[39m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrites\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2649\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2650\u001b[39m \u001b[43m    \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2651\u001b[39m \u001b[43m    \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43maccept_push\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2652\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2653\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[32m   2654\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_output\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2655\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubgraphs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqueue\u001b[49m\u001b[43m.\u001b[49m\u001b[43mEmpty\u001b[49m\n\u001b[32m   2656\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2657\u001b[39m loop.after_tick()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/multi-agent/kg_env/lib/python3.13/site-packages/langgraph/pregel/_runner.py:162\u001b[39m, in \u001b[36mPregelRunner.tick\u001b[39m\u001b[34m(self, tasks, reraise, timeout, retry_policy, get_waiter, schedule_task)\u001b[39m\n\u001b[32m    160\u001b[39m t = tasks[\u001b[32m0\u001b[39m]\n\u001b[32m    161\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m162\u001b[39m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    163\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    164\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    166\u001b[39m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    167\u001b[39m \u001b[43m                \u001b[49m\u001b[43m_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    168\u001b[39m \u001b[43m                \u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    169\u001b[39m \u001b[43m                \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    170\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[43m                \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[43m                \u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    175\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    176\u001b[39m     \u001b[38;5;28mself\u001b[39m.commit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    177\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/multi-agent/kg_env/lib/python3.13/site-packages/langgraph/pregel/_retry.py:42\u001b[39m, in \u001b[36mrun_with_retry\u001b[39m\u001b[34m(task, retry_policy, configurable)\u001b[39m\n\u001b[32m     40\u001b[39m     task.writes.clear()\n\u001b[32m     41\u001b[39m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43mproc\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     44\u001b[39m     ns: \u001b[38;5;28mstr\u001b[39m = config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/multi-agent/kg_env/lib/python3.13/site-packages/langgraph/_internal/_runnable.py:657\u001b[39m, in \u001b[36mRunnableSeq.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    655\u001b[39m     \u001b[38;5;66;03m# run in context\u001b[39;00m\n\u001b[32m    656\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config, run) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m--> \u001b[39m\u001b[32m657\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    658\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    659\u001b[39m     \u001b[38;5;28minput\u001b[39m = step.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/multi-agent/kg_env/lib/python3.13/site-packages/langgraph/_internal/_runnable.py:401\u001b[39m, in \u001b[36mRunnableCallable.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    399\u001b[39m         run_manager.on_chain_end(ret)\n\u001b[32m    400\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m     ret = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    402\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.recurse \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable):\n\u001b[32m    403\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ret.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/multi-agent/financial_kg_system/evals/notebooks/../../src/ma_finkg/kg_construction_graph.py:139\u001b[39m, in \u001b[36mFinancialKGConstructionGraph._knowledge_extraction_expert_node\u001b[39m\u001b[34m(self, state)\u001b[39m\n\u001b[32m    137\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_knowledge_extraction_expert_node\u001b[39m(\u001b[38;5;28mself\u001b[39m, state: GraphState) -> Dict[\u001b[38;5;28mstr\u001b[39m, Any]:\n\u001b[32m    138\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Knowledge Extraction Expert node - NER and RE.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mknowledge_extraction_expert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/multi-agent/financial_kg_system/src/ma_finkg/agents/knowledge_extraction_expert.py:224\u001b[39m, in \u001b[36mKnowledgeExtractionExpert.__call__\u001b[39m\u001b[34m(self, state)\u001b[39m\n\u001b[32m    222\u001b[39m \u001b[38;5;66;03m# Step 2: RE pass (optional toggle for faster NER-only testing)\u001b[39;00m\n\u001b[32m    223\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.enable_re:\n\u001b[32m--> \u001b[39m\u001b[32m224\u001b[39m     all_triples, _ = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_extract_relations_with_feedback\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mall_entities\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43montology\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    225\u001b[39m     elapsed = get_elapsed_time()\n\u001b[32m    226\u001b[39m     print_progress(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m[\u001b[39m\u001b[38;5;132;01m{\u001b[39;00melapsed\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.1f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33ms] RE completed: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(all_triples)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m filtered triples\u001b[39m\u001b[33m\"\u001b[39m, final=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/multi-agent/financial_kg_system/src/ma_finkg/agents/knowledge_extraction_expert.py:311\u001b[39m, in \u001b[36mKnowledgeExtractionExpert._extract_relations_with_feedback\u001b[39m\u001b[34m(self, text, entities, ontology)\u001b[39m\n\u001b[32m    309\u001b[39m     elapsed = get_elapsed_time()\n\u001b[32m    310\u001b[39m     print_progress(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m[\u001b[39m\u001b[38;5;132;01m{\u001b[39;00melapsed\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.1f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33ms] Processing relation \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(ontology.relation_types)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrelation_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m311\u001b[39m     triples = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mre_expert\u001b[49m\u001b[43m.\u001b[49m\u001b[43mextract_relations_by_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrelation_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mentities\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43montology\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    312\u001b[39m     all_triples.extend(triples)\n\u001b[32m    314\u001b[39m \u001b[38;5;66;03m# Pseudocode: dedup(triples) - remove exact duplicates  \u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/multi-agent/financial_kg_system/src/ma_finkg/agents/knowledge_extraction_expert.py:98\u001b[39m, in \u001b[36mREExpert.extract_relations_by_type\u001b[39m\u001b[34m(self, text, relation_type, entities, ontology)\u001b[39m\n\u001b[32m     96\u001b[39m \u001b[38;5;66;03m# Step 2: For each head, extract tail entities (relation-aware)\u001b[39;00m\n\u001b[32m     97\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m head_entity \u001b[38;5;129;01min\u001b[39;00m head_candidates:\n\u001b[32m---> \u001b[39m\u001b[32m98\u001b[39m     tail_candidates = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_extract_tail_entities\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     99\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhead_entity\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtail_types\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtail_types\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mEntity\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m    100\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrelation_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43montology\u001b[49m\n\u001b[32m    101\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    103\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m tail_entity \u001b[38;5;129;01min\u001b[39;00m tail_candidates:\n\u001b[32m    104\u001b[39m         \u001b[38;5;66;03m# Apply pseudocode filtering: in_NER(h) and in_NER(t) and type_ok(R, h, t)\u001b[39;00m\n\u001b[32m    105\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m head_entity.lower().strip() != tail_entity.lower().strip():\n\u001b[32m    106\u001b[39m             \u001b[38;5;66;03m# Check in_NER(h) and in_NER(t)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/multi-agent/financial_kg_system/src/ma_finkg/agents/knowledge_extraction_expert.py:170\u001b[39m, in \u001b[36mREExpert._extract_tail_entities\u001b[39m\u001b[34m(self, text, head_entity, tail_type, relation_type, ontology)\u001b[39m\n\u001b[32m    162\u001b[39m prompt = prompts[\u001b[33m'\u001b[39m\u001b[33mre_tail_extraction_prompt\u001b[39m\u001b[33m'\u001b[39m].format(\n\u001b[32m    163\u001b[39m     head_entity=head_entity,\n\u001b[32m    164\u001b[39m     tail_type=tail_type,\n\u001b[32m    165\u001b[39m     relation_name=relation_type,\n\u001b[32m    166\u001b[39m     text=text\n\u001b[32m    167\u001b[39m )\n\u001b[32m    169\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m170\u001b[39m     response = \u001b[43mtimeout_llm_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mllm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mHumanMessage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    171\u001b[39m     response_text = response.content.strip()\n\u001b[32m    173\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/multi-agent/financial_kg_system/src/ma_finkg/utils/llm_factory.py:17\u001b[39m, in \u001b[36mtimeout_llm_call\u001b[39m\u001b[34m(llm, messages, timeout_seconds)\u001b[39m\n\u001b[32m     15\u001b[39m future = executor.submit(_call)\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfuture\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout_seconds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m FutureTimeoutError:\n\u001b[32m     19\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m⏰ HUNG: LLM call exceeded \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtimeout_seconds\u001b[38;5;132;01m}\u001b[39;00m\u001b[33ms\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.3_1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py:451\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    448\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state == FINISHED:\n\u001b[32m    449\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.__get_result()\n\u001b[32m--> \u001b[39m\u001b[32m451\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_condition\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    453\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[32m    454\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.3_1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/threading.py:363\u001b[39m, in \u001b[36mCondition.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    361\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    362\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m timeout > \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m363\u001b[39m         gotit = \u001b[43mwaiter\u001b[49m\u001b[43m.\u001b[49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    364\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    365\u001b[39m         gotit = waiter.acquire(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Evaluate NYT11-HRL relation extraction\n",
    "\n",
    "import json\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "\n",
    "rows = 10 # Test: 370\n",
    "batch_size = 10\n",
    "comparison_file = \"nyt11_clean_comparison.json\"\n",
    "\n",
    "comparison_path = Path(comparison_file)\n",
    "total_tp = total_fp = total_fn = 0\n",
    "if comparison_path.exists():\n",
    "    with open(comparison_path, 'r') as f:\n",
    "        comparison_data = json.load(f)\n",
    "    # Get already processed sentences from existing comparison data\n",
    "    processed_sentences = set(item['sentence'] for item in comparison_data)\n",
    "    \n",
    "    # Recalculate metrics from existing data\n",
    "    for item in comparison_data:\n",
    "        gold_set = set(tuple(rel) for rel in item['gold'])\n",
    "        sys_set = set(tuple(rel) for rel in item['sys'])\n",
    "        total_tp += len(gold_set & sys_set)\n",
    "        total_fp += len(sys_set - gold_set)\n",
    "        total_fn += len(gold_set - sys_set)\n",
    "    \n",
    "    print(f\"Resuming from {len(processed_sentences)} processed sentences\")\n",
    "else:\n",
    "    comparison_data = []\n",
    "    processed_sentences = set()\n",
    "\n",
    "# Group relations by sentence to avoid duplicate processing\n",
    "sentence_relations = defaultdict(list)\n",
    "sentence_cache = {}\n",
    "\n",
    "# Collect all gold relations by sentence\n",
    "for i in range(rows):\n",
    "    row = test_df.iloc[i]\n",
    "    text = row['sentext'].strip()\n",
    "    gold_relation = [row['em1'].lower(), row['rtext'], row['em2'].lower()]\n",
    "    sentence_relations[text].append(gold_relation)\n",
    "\n",
    "remaining_sentences = {text: relations for text, relations in sentence_relations.items() \n",
    "                      if text not in processed_sentences}\n",
    "\n",
    "print(f\"Processing {len(remaining_sentences)}/{len(sentence_relations)} remaining sentences...\")\n",
    "\n",
    "# Process each remaining sentence\n",
    "for sentence_idx, (text, gold_relations) in enumerate(remaining_sentences.items(), 1):\n",
    "    if text not in sentence_cache:\n",
    "        print(f\"Processing sentence {len(processed_sentences) + sentence_idx}/{len(sentence_relations)}...\")\n",
    "        result = kg_system.construct_kg(text)\n",
    "        sys_triples = result['finalize'].get(\"revised_triples\", []) if 'finalize' in result else []\n",
    "        \n",
    "        sys_relations = []\n",
    "        for triple in sys_triples:\n",
    "            if hasattr(triple, 'head') and hasattr(triple, 'relation') and hasattr(triple, 'tail'):\n",
    "                sys_relations.append([\n",
    "                    triple.head.lower(),\n",
    "                    triple.relation,\n",
    "                    triple.tail.lower()\n",
    "                ])\n",
    "        sentence_cache[text] = sys_relations\n",
    "    \n",
    "    sys_relations = sentence_cache[text]\n",
    "    \n",
    "    # skip empty-empty cases\n",
    "    if gold_relations or sys_relations:\n",
    "        comparison_data.append({\n",
    "            \"gold\": gold_relations,\n",
    "            \"sys\": sys_relations,\n",
    "            \"sentence\": text \n",
    "        })\n",
    "    \n",
    "    # Calculate metrics for this sentence\n",
    "    gold_set = set(tuple(rel) for rel in gold_relations)\n",
    "    sys_set = set(tuple(rel) for rel in sys_relations)\n",
    "    \n",
    "    tp = len(gold_set & sys_set)\n",
    "    fp = len(sys_set - gold_set) \n",
    "    fn = len(gold_set - sys_set)\n",
    "\n",
    "    total_tp += tp\n",
    "    total_fp += fp\n",
    "    total_fn += fn\n",
    "\n",
    "    # Save progress\n",
    "    if sentence_idx % batch_size == 0 or sentence_idx == len(remaining_sentences):\n",
    "        with open(comparison_path, 'w') as f:\n",
    "            json.dump(comparison_data, f, indent=2)\n",
    "        print(f\"Progress saved: {len(comparison_data)} comparisons\")\n",
    "\n",
    "# Export final data\n",
    "print(f\"\\nExporting {len(comparison_data)} non-empty sentence comparisons...\")\n",
    "with open(comparison_file, 'w') as f:\n",
    "    json.dump(comparison_data, f, indent=2)\n",
    "\n",
    "# Summary statistics\n",
    "print(f\"FINAL EXTRACTION: {sum(len(item['sys']) for item in comparison_data)} System Relations, {sum(len(item['gold']) for item in comparison_data)} Gold Relations\")\n",
    "print(f\"Non-empty cases: {len(comparison_data)}/{len(sentence_relations)} sentences\")\n",
    "print(\"Saved clean comparison to nyt11_clean_comparison.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fdd445a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate micro F1 for relation extraction\n",
    "\n",
    "precision = total_tp / (total_tp + total_fp) if total_tp + total_fp > 0 else 0\n",
    "recall = total_tp / (total_tp + total_fn) if total_tp + total_fn > 0 else 0  \n",
    "f1 = 2 * precision * recall / (precision + recall) if precision + recall > 0 else 0\n",
    "\n",
    "print(f\"\\nNYT11-HRL Relation Extraction Micro F1 Results ({rows} samples):\")\n",
    "print(f\"Precision: {precision:.3f}\")\n",
    "print(f\"Recall: {recall:.3f}\")\n",
    "print(f\"F1: {f1:.3f}\")\n",
    "print(f\"Total TP: {total_tp}, FP: {total_fp}, FN: {total_fn}\")\n",
    "\n",
    "# Show sample comparisons from exported data\n",
    "print(f\"\\n=== SAMPLE COMPARISONS FROM CLEAN EXPORT ===\")\n",
    "sample_comparisons = comparison_data[:5] \n",
    "for i, item in enumerate(sample_comparisons, 1):\n",
    "    print(f\"\\nSample {i}:\")\n",
    "    print(f\"Gold: {item['gold']}\")\n",
    "    print(f\"Sys:  {item['sys']}\")\n",
    "    print(f\"Sentence: {item['sentence']}\")\n",
    "    \n",
    "    # Show match analysis\n",
    "    gold_set = set(tuple(rel) for rel in item['gold'])\n",
    "    sys_set = set(tuple(rel) for rel in item['sys'])\n",
    "    \n",
    "    if gold_set & sys_set:\n",
    "        print(f\"✓ MATCHES: {list(gold_set & sys_set)}\")\n",
    "    if sys_set - gold_set:\n",
    "        print(f\"✗ FALSE POSITIVES: {list(sys_set - gold_set)}\")\n",
    "    if gold_set - sys_set:\n",
    "        print(f\"✗ FALSE NEGATIVES: {list(gold_set - sys_set)}\")\n",
    "        \n",
    "print(f\"\\n=== ERROR ANALYSIS BENEFITS ===\")\n",
    "print(f\"• Total cases: {len(sentence_relations)} unique sentences\")\n",
    "print(f\"• Non-empty cases: {len(comparison_data)} ({len(comparison_data)/len(sentence_relations)*100:.1f}%)\")\n",
    "print(f\"• Avoided {len(sentence_relations) - len(comparison_data)} empty cases that would dilute analysis\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 5514103,
     "sourceId": 9132426,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30746,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "kg_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 269.355408,
   "end_time": "2024-08-08T15:20:59.425391",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-08-08T15:16:30.069983",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
